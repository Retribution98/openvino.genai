// Copyright (C) 2025 Intel Corporation
// SPDX-License-Identifier: Apache-2.0

import util from "node:util";
import { WhisperPipeline as WhisperPipelineWrapper } from "../addon.js";
import type { WhisperDecodedResults } from "../addon.js";
import {
  WhisperGenerationConfig,
  WhisperPipelineProperties,
  StreamingStatus,
} from "../utils.js";
import { Tokenizer } from "../tokenizer.js";

/**
 * Options for Whisper generation methods.
 */
export type WhisperGenerateOptions = {
  /** Generation configuration (e.g. language, task, return_timestamps). */
  generationConfig?: WhisperGenerationConfig;
  /** Callback invoked with each decoded text chunk; return StreamingStatus to control generation. */
  streamer?: (chunk: string) => StreamingStatus;
};

/**
 * Pipeline for automatic speech recognition using Whisper models.
 *
 * Expects raw audio normalized to approximately [-1, 1] at 16 kHz sample rate.
 * Use a WAV file or decode audio to Float32Array before calling generate().
 */
export class WhisperPipeline {
  protected readonly modelPath: string;
  protected readonly device: string;
  protected pipeline: WhisperPipelineWrapper | null = null;
  protected readonly properties: WhisperPipelineProperties;

  /**
   * Construct a Whisper pipeline from a folder containing model IRs and tokenizer.
   * @param modelPath - Path to the folder with model IRs and tokenizer (e.g. openvino_encoder_model.xml, preprocessor_config.json).
   * @param device - Inference device (e.g. "CPU", "GPU").
   * @param properties - Device and pipeline properties (e.g. word_timestamps: true, CACHE_DIR: "cache").
   */
  constructor(
    modelPath: string,
    device: string,
    properties: WhisperPipelineProperties = {},
  ) {
    this.modelPath = modelPath;
    this.device = device;
    this.properties = properties;
  }

  /**
   * Load the pipeline. Must be called once before generate().
   */
  async init(): Promise<void> {
    const pipeline = new WhisperPipelineWrapper();
    const initPromise = util.promisify(pipeline.init.bind(pipeline));
    await initPromise(this.modelPath, this.device, this.properties);
    this.pipeline = pipeline;
  }

  /**
   * Stream speech recognition chunks as an async iterator.
   * @param rawSpeech - Audio samples as Float32Array or number[], normalized to ~[-1, 1], 16 kHz.
   * @param options - Optional generation config (e.g. language, task, return_timestamps).
   * @returns Async iterator yielding decoded text chunks.
   */
  stream(
    rawSpeech: Float32Array | number[],
    options?: WhisperGenerationConfig,
  ): AsyncIterableIterator<string> {
    if (!this.pipeline) throw new Error("WhisperPipeline is not initialized");
    const generationConfig =
      options && Object.keys(options).length > 0 ? options : undefined;

    let streamingStatus = StreamingStatus.RUNNING;
    const queue: { done: boolean; chunk: string }[] = [];
    type ResolveFunction = (arg: { value: string; done: boolean }) => void;
    let resolvePromise: ResolveFunction | null = null;
    let rejectPromise: ((reason?: unknown) => void) | null = null;

    const callback = (error: Error | null, result: WhisperDecodedResults) => {
      if (error) {
        if (rejectPromise) {
          rejectPromise(error);
          resolvePromise = null;
          rejectPromise = null;
        }
        return;
      }
      const fullText = result.texts?.[0] ?? "";
      if (resolvePromise) {
        resolvePromise({ done: true, value: fullText });
        resolvePromise = null;
        rejectPromise = null;
      } else {
        queue.push({ done: true, chunk: fullText });
      }
    };

    const streamer = (chunk: string): StreamingStatus => {
      if (resolvePromise) {
        resolvePromise({ done: false, value: chunk });
        resolvePromise = null;
        rejectPromise = null;
      } else {
        queue.push({ done: false, chunk });
      }
      return streamingStatus;
    };

    this.pipeline.generate(rawSpeech, generationConfig, streamer, callback);

    return {
      async next() {
        const data = queue.shift();
        if (data) {
          return { value: data.chunk, done: data.done };
        }
        return new Promise<IteratorResult<string>>((resolve, reject) => {
          resolvePromise = resolve;
          rejectPromise = reject;
        });
      },
      async return() {
        streamingStatus = StreamingStatus.CANCEL;
        return { done: true, value: "" };
      },
      [Symbol.asyncIterator]() {
        return this;
      },
    };
  }

  /**
   * Run speech recognition on raw audio samples.
   * @param rawSpeech - Audio samples as Float32Array or number[], normalized to ~[-1, 1], 16 kHz.
   * @param options - Optional generation config and/or streamer callback.
   * @returns Decoded texts, scores, optional chunks with timestamps, and perf metrics.
   */
  async generate(
    rawSpeech: Float32Array | number[],
    options: WhisperGenerateOptions = {},
  ): Promise<WhisperDecodedResults> {
    if (!this.pipeline) throw new Error("WhisperPipeline is not initialized");
    const { generationConfig, streamer } = options;
    const configForNative =
      generationConfig && Object.keys(generationConfig).length > 0 ? generationConfig : undefined;
    const boundGenerate = this.pipeline.generate.bind(this.pipeline);
    if (streamer != null) {
      return await new Promise<WhisperDecodedResults>((resolve, reject) => {
        boundGenerate(rawSpeech, configForNative ?? {}, streamer, (err, res) =>
          err ? reject(err) : resolve(res),
        );
      });
    }
    return await new Promise<WhisperDecodedResults>((resolve, reject) => {
      boundGenerate(rawSpeech, configForNative ?? {}, (err, res) =>
        err ? reject(err) : resolve(res),
      );
    });
  }

  /**
   * Get the pipeline tokenizer.
   */
  getTokenizer(): Tokenizer {
    if (!this.pipeline) throw new Error("WhisperPipeline is not initialized");
    return this.pipeline.getTokenizer();
  }

  /**
   * Get current generation config (language, task, return_timestamps, etc.).
   */
  getGenerationConfig(): Partial<WhisperGenerationConfig> {
    if (!this.pipeline) throw new Error("WhisperPipeline is not initialized");
    return this.pipeline.getGenerationConfig();
  }

  /**
   * Update generation config (e.g. language, task, return_timestamps).
   */
  setGenerationConfig(config: WhisperGenerationConfig): void {
    if (!this.pipeline) throw new Error("WhisperPipeline is not initialized");
    this.pipeline.setGenerationConfig(config);
  }
}
